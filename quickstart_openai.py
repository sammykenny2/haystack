# SPDX-FileCopyrightText: 2022-present deepset GmbH <info@deepset.ai>
#
# SPDX-License-Identifier: Apache-2.0

"""
Haystack å¿«é€Ÿå…¥é–€ç¯„ä¾‹ - å»ºç«‹ä¸€å€‹ç°¡å–®çš„ RAG æ‡‰ç”¨ç¨‹å¼

é€™å€‹ç¯„ä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨ Haystack å»ºç«‹ä¸€å€‹åŸºæœ¬çš„æª¢ç´¢å¢å¼·ç”Ÿæˆ (RAG) ç³»çµ±
"""

from haystack import Document, Pipeline
from haystack.components.builders import ChatPromptBuilder
from haystack.components.generators.chat import OpenAIChatGenerator
from haystack.components.retrievers import InMemoryBM25Retriever
from haystack.dataclasses import ChatMessage
from haystack.document_stores.in_memory import InMemoryDocumentStore
from haystack.utils import Secret


def main():
    """ä¸»ç¨‹å¼:å»ºç«‹ä¸¦é‹è¡Œ RAG Pipeline"""

    # ====== æ­¥é©Ÿ 1: å»ºç«‹æ–‡ä»¶å„²å­˜ä¸¦å¯«å…¥è³‡æ–™ ======
    print("ğŸ“š æ­¥é©Ÿ 1: å»ºç«‹æ–‡ä»¶å„²å­˜...")
    document_store = InMemoryDocumentStore()
    document_store.write_documents(
        [
            Document(content="My name is Jean and I live in Paris."),
            Document(content="My name is Mark and I live in Berlin."),
            Document(content="My name is Giorgio and I live in Rome."),
        ]
    )
    print(f"   âœ“ å·²å¯«å…¥ {document_store.count_documents()} å€‹æ–‡ä»¶\n")

    # ====== æ­¥é©Ÿ 2: å®šç¾©æç¤ºæ¨¡æ¿ ======
    print("ğŸ’¬ æ­¥é©Ÿ 2: å®šç¾©æç¤ºæ¨¡æ¿...")
    prompt_template = [
        ChatMessage.from_system(
            """
            Given these documents, answer the question.
            Documents:
            {% for doc in documents %}
                {{ doc.content }}
            {% endfor %}
            Question:
            """
        ),
        ChatMessage.from_user("{{question}}"),
        ChatMessage.from_system("Answer:"),
    ]
    print("   âœ“ æç¤ºæ¨¡æ¿å·²å»ºç«‹\n")

    # ====== æ­¥é©Ÿ 3: å»ºç«‹çµ„ä»¶ ======
    print("ğŸ”§ æ­¥é©Ÿ 3: å»ºç«‹ Pipeline çµ„ä»¶...")
    retriever = InMemoryBM25Retriever(document_store=document_store)
    prompt_builder = ChatPromptBuilder(template=prompt_template, required_variables=["documents", "question"])

    # æ³¨æ„:éœ€è¦è¨­å®š OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸
    # å¯ä»¥æ”¹ç”¨å…¶ä»–ç”Ÿæˆå™¨,ä¾‹å¦‚ Hugging Face æ¨¡å‹
    llm = OpenAIChatGenerator(api_key=Secret.from_env_var("OPENAI_API_KEY"), model="gpt-4o-mini")
    print("   âœ“ å·²å»ºç«‹ Retriever")
    print("   âœ“ å·²å»ºç«‹ PromptBuilder")
    print("   âœ“ å·²å»ºç«‹ LLM (OpenAI)\n")

    # ====== æ­¥é©Ÿ 4: çµ„è£ Pipeline ======
    print("ğŸ”— æ­¥é©Ÿ 4: çµ„è£ Pipeline...")
    rag_pipeline = Pipeline()
    rag_pipeline.add_component("retriever", retriever)
    rag_pipeline.add_component("prompt_builder", prompt_builder)
    rag_pipeline.add_component("llm", llm)
    print("   âœ“ å·²æ·»åŠ æ‰€æœ‰çµ„ä»¶\n")

    # ====== æ­¥é©Ÿ 5: é€£æ¥çµ„ä»¶ ======
    print("ğŸ”Œ æ­¥é©Ÿ 5: é€£æ¥çµ„ä»¶...")
    rag_pipeline.connect("retriever", "prompt_builder.documents")
    rag_pipeline.connect("prompt_builder", "llm")
    print("   âœ“ çµ„ä»¶é€£æ¥å®Œæˆ\n")

    # ====== æ­¥é©Ÿ 6: é‹è¡Œ Pipeline ======
    print("ğŸš€ æ­¥é©Ÿ 6: é‹è¡Œ Pipeline...")
    question = "Who lives in Paris?"
    print(f"   å•é¡Œ: {question}\n")

    results = rag_pipeline.run({"retriever": {"query": question}, "prompt_builder": {"question": question}})

    # ====== æ­¥é©Ÿ 7: é¡¯ç¤ºçµæœ ======
    print("âœ¨ çµæœ:")
    print(f"   å›ç­”: {results['llm']['replies'][0].content}\n")

    # é¡¯ç¤ºå®Œæ•´çš„ Pipeline çµæ§‹
    print("ğŸ“Š Pipeline çµæ§‹:")
    rag_pipeline.show()


if __name__ == "__main__":
    print("=" * 60)
    print("  Haystack RAG Pipeline å¿«é€Ÿå…¥é–€ç¯„ä¾‹")
    print("=" * 60)
    print()

    try:
        main()
        print("\n" + "=" * 60)
        print("  âœ“ åŸ·è¡ŒæˆåŠŸ!")
        print("=" * 60)
    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        print("\næç¤º:")
        print("1. ç¢ºä¿å·²å®‰è£ haystack-ai: pip install haystack-ai")
        print("2. è¨­å®š OpenAI API Key: $env:OPENAI_API_KEY='your-key'")
        print("3. æˆ–ä¿®æ”¹ç¨‹å¼ç¢¼ä½¿ç”¨å…¶ä»– LLM ä¾›æ‡‰å•†")
